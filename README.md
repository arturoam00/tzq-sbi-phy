This repository contains code to automate the creation of [DAGMan
Workflows](https://htcondor.readthedocs.io/en/latest/automated-workflows/index.html) for high-energy
physics simulations with [MadMiner](https://github.com/madminer-tool/madminer). The graph below
shows the typical workflow. The steps between `Setup` and `Run Augmentation` correspond to the
generation of physical events, showering and detector response, and the creation of physical
observables. They can be run in parallel for different processes or for the same one, with
appropriate random seed initialization.

<p align="center">
  <img src=".assets/graph.png" width="400">
</p>

The advantage of using DAGMan worflows is that we just need to submit one (meta) DAG to get the
desired NumPy files used for model training. The disadvantage is that we need to know DAG syntax to
define the worflow. This repository helps with that using `.yaml` files to define the configuration
for the different steps in the worflow to generate the whole DAG structure. This will typically
consist of one main meta-DAG (the one submitted) that points to several "sub-dag" files to compose
the structure. We also include the option to *redo* a DAG from a given phase in the workflow. This
is useful for example if you want to extract new observables from your `.root` files, for which only
the phases `Run Delphes` and `Run Augmentation` need to be re-run.

All this can be done using the `madminer-dag` command. 

# Configuration folder structure

`madminer-dag` expects the following folder structure
```
<Folder name>
├── benchmarks.yml
├── dag.conf
├── dag.yml
└── observables.yml
```
Examples of such folders can be found in the `conf` folder. 

+ `dag.yml` is the main configuration file (see `conf/experiment_so_cht/dag.yml` for an example).
    There we define, among other, the paths to the different *simulation cards* used, the number of
    independent runs for each process and the output paths for the generated files. 
+ `dag.conf` contains global variables that control the behaviour of the DAG workflow. See
    [here](https://htcondor.readthedocs.io/en/latest/automated-workflows/dagman-advance-functionality.html#per-dag-config)
    for information.
+ `benchmarks.yml` and `observables.yml` define the configuration for the phases `Setup` and `Run
    Analysis`, respectively. These are separated from the global `dag.yml` mainly because they are
    typically lengthy files, but could be understood as part of it. 

# Special configuration fields
All configurations in `dag.yml`, should be straightforward to understand if you are familiar with
MadMiner. You can check the
[tutorial](https://github.com/madminer-tool/madminer/tree/main/examples/tutorial_particle_physics)
first if this is not the case. There are a couple of fields that need explanation. A *process* for
event generation is defined in `dag.yml` as a set of key-value pairs under the
`processes` key. Apart from the paths to the different simulation cards and the benchmark point
ID, we include the keys:

- `runs`: Number of independent times to run the process.
- `n_subprocesses`: Needed to calculate the correct random seed for the different independent
  `runs`. See [here](https://answers.launchpad.net/mg5amcnlo/+question/254698) for explanation.
- `reweight_card_insert`: Path to a file containing the lines to be inserted at the top of the
  reweight card automatically generated by MadMiner. Useful in cases where we need to change the
  MadGraph process definition to change the *new physics* parameters for SMEFTSim (`change process
  ... NP=1`). Can be `none` if not needed.

# Get started
Clone the repo 
```bash 
git clone https://github.com/arturoam00/tzq-sbi-phy
```
and install the dependencies
```bash 
cd tzq-sbi-phy
python3 -m venv .venv && source .venv/bin/activate
python -m pip install -r requirements.txt
```

# Try the examples

From now on we will use the configurations of the paper under the `conf` folder to illustrate the
usage of `madminer-dag` with examples. Only the files under `conf` and `cards` need modification if you
want to try another process. 

## Create a DAG and submit it

To create a [DAG](https://htcondor.readthedocs.io/en/latest/automated-workflows/index.html) for the
one dimensional experiment, run
```bash
madminer-dag create -c conf/experiment_so_cht
```
This creates a **dag folder** under `dag/`. In this case you can inspect the folder `dag/experiment_so_cht` to
see the generated subdags and helper files. The main DAG file has been created under
`dag/experiment_so_cht/experiment_so_cht.dag.`Submit it using
```
condor_submit_dag dag/experiment_so_cht/experiment_so_cht.dag
```

The created dag folders contain

## Redoing experiments
It might be the case that you need to redo the pipeline from an intermediate step. Try 
```bash
madminer-dag redo --help
```
to see the different options available. You first need an already generated dag folder to start
redoing phases from. If you followed the example above, this is `dag/experiment_so_cht`. To redo
just the augmentation phase, do
```bash
madminer-dag redo -e `dag/experiment_so_cht` -p augmentation
```
To make this work we parse the DAG status file (`*.dag.status`) generated after submission of the
DAG file and identify the DAG nodes that need to be redone and mark the rest as completed, using a
[DAG rescue
file](https://htcondor.readthedocs.io/en/latest/automated-workflows/dagman-completion.html#the-rescue-dag).

[!NOTE]
Creating a rescue DAGs to redo an experiment is a bit "hacky", since rescue DAGs are used to resume
a DAG from the point it failed. You have to be careful then to submit the correct rescue DAG if
there are multiple present in the DAG folder. You can specify the rescue number with `--rescue`
```
madminer-dag -e dag/experiment_so_cht -p augmentation --rescue 99
```
And launch the correct rescue DAG
```
condor_submit_dag -DoRescueFrom 99 dag/experiment_so_cht/experiment_so_cht.dag 
```

